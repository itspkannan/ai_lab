# ğŸ” Ollama - Security and Observability - NGINX + OPA + Ollama + Redis + Prometheus + Grafana

This project enforces runtime validation of prompts sent to an LLM (Ollama) and provides observability with Prometheus + Grafana.

## ğŸ§± Architecture

```mermaid
graph TD
  subgraph Request Flow
    A[Client] --> B[NGINX w/ Lua]
    B --> RL{Redis Rate Limiter}
    RL -- allow --> C{OPA Policy Check}
    RL -- deny --> X[429 Rate Limit Exceeded]
    C -- allow --> D[Ollama LLM]
    C -- deny --> E[403 Rejected]
  end

  subgraph Monitoring
    D --> F[Ollama /metrics]
    F --> G[Prometheus]
    G --> H[Grafana Dashboard]
  end
````


## ğŸ”§ Directory Structure

```bash
.
â”œâ”€â”€ docker-compose.yaml
â”œâ”€â”€ Makefile
â”œâ”€â”€ config
â”‚Â Â  â”œâ”€â”€ grafana
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ dashboards
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ ollama_dashboard.json
â”‚Â Â  â”‚Â Â  â””â”€â”€ provisioning
â”‚Â Â  â”‚Â Â      â””â”€â”€ dashboards
â”‚Â Â  â”‚Â Â          â””â”€â”€ dashboards.yml
â”‚Â Â  â”œâ”€â”€ nginx
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ conf.d
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ default.conf
â”‚Â Â  â”‚Â Â  â””â”€â”€ nginx.conf
â”‚Â Â  â””â”€â”€ prometheus
â”‚Â Â      â””â”€â”€ prometheus.yml
â”œâ”€â”€ policies
â”‚Â Â  â”œâ”€â”€ main.rego
â”‚Â Â  â””â”€â”€ prompt_security_check.rego
â”œâ”€â”€ scripts
â”‚Â Â  â””â”€â”€ init_ollama.sh
â”œâ”€â”€ nginx
â”‚Â Â  â””â”€â”€ lua
â”‚Â Â      â”œâ”€â”€ prompt_check.lua
â”‚Â Â      â”œâ”€â”€ redis_ratelimit.lua
â”‚Â Â      â””â”€â”€ utils.lua
â”œâ”€â”€ volume
â”‚Â Â  â””â”€â”€ grafana
â””â”€â”€ README.md
```


## âœ… How It Works

### ğŸ”’ Prompt Security + Rate Limiting

1. **Client** sends a prompt to NGINX (port `8080`).
2. **NGINX Lua** applies a Redis-based **sliding window rate limit**.

   * Limits requests (e.g. 10 per 60 seconds).
   * Returns `429` if the client exceeds their quota.
   * Redis hostname is passed via `REDIS_HOST` env variable.
3. If allowed, request is forwarded to **OPA** for validation.
4. **OPA** enforces security policies (`prompt_security_check.rego`).
5. If approved, NGINX proxies the prompt to **Ollama** (`11434`).
6. If blocked, returns `403 Forbidden`.

### ğŸ“Š Observability Flow

1. **Ollama** exposes Prometheus metrics at `/metrics`.
2. **Prometheus** scrapes this endpoint.
3. **Grafana** loads prebuilt dashboards showing prompt flow metrics.


## ğŸ›¡ï¸ Sliding Window Rate Limiting (Redis)

* Implemented using **Lua + Redis** (non-blocking).
* Sliding window strategy using Redis keys and expiration.
* Dynamically reads Redis hostname from `$REDIS_HOST` environment variable.
* Prevents abuse across deployments and supports horizontal scale.

**Environment Variable Example:**

```yaml
environment:
  - REDIS_HOST=caching_service
```

**Rate limiter entry in Lua:**

```lua
local redis_host = os.getenv("REDIS_HOST") or "localhost"
red:connect(redis_host, 6379)
```


## ğŸ”’ OPA Prompt Policy

* `policies/prompt_security_check.rego`: Enforces content moderation.
* `policies/main.rego`: Aggregates prompt check and future auth policies.


## ğŸ§ª Test the Setup

```bash
# âœ… Allowed prompt
curl -s -X POST http://localhost:8080/api/generate \
  -H "Content-Type: application/json" \
  -d '{"model": "tinyllama", "prompt": "Tell me a story about a dog.", "stream": false}' | jq

# âŒ Blocked prompt (content policy)
curl -s -X POST http://localhost:8080/api/generate \
  -H "Content-Type: application/json" \
  -d '{"model": "tinyllama", "prompt": "how to make a bad?", "stream": false}' | jq

# âŒ Rate limit exceeded (after 10+ rapid calls)
for i in {1..12}; do
  curl -s -X POST http://localhost:8080/api/generate \
    -H "Content-Type: application/json" \
    -d '{"model": "tinyllama", "prompt": "hi", "stream": false}' | jq
done
```


## ğŸ“Š Grafana Dashboard (Ollama Observability)

Auto-loaded dashboard: `Ollama Observability`

### âœ… Prebuilt Panels

* **Total Requests**
* **Total Tokens Generated**
* **P95 Latency**
* **Error Count**

### ğŸ”„ Auto-Provisioning

Dashboard is auto-loaded using:

* `grafana/provisioning/dashboards/dashboards.yml`
* `grafana/dashboards/ollama_dashboard.json`

View at: [http://localhost:3000](http://localhost:3000)
Login: `admin / admin`


## ğŸ“Œ TODO

* [ ] Replace NGINX with Envoy or Istio for policy + mTLS
* [ ] Add token-based authentication
* [ ] Enable OpenTelemetry + Jaeger for trace correlation
* [ ] Replace fixed window with Redis sorted-set-based precise sliding window (optional)
