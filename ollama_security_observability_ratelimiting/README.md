# ğŸ” Ollama - Security and Observability - NGINX + OPA + Ollama + Observability

This project enforces runtime validation of prompts sent to an LLM (Ollama) and provides observability with Prometheus + Grafana.

## ğŸ§± Architecture

```mermaid
graph TD
  subgraph Request Flow
    A[Client] --> B[NGINX w/ Lua]
    B --> C{OPA Policy Check}
    C -- allow --> D[Ollama LLM]
    C -- deny --> E[403 Rejected]
  end

  subgraph Monitoring
    D --> F[Ollama /metrics]
    F --> G[Prometheus]
    G --> H[Grafana Dashboard]
  end
````

## ğŸ”§ Directory Structure

```bash
.
â”œâ”€â”€ docker-compose.yaml
â”œâ”€â”€ Makefile
â”œâ”€â”€ config
â”‚Â Â  â”œâ”€â”€ grafana
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ dashboards
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ ollama_dashboard.json
â”‚Â Â  â”‚Â Â  â””â”€â”€ provisioning
â”‚Â Â  â”‚Â Â      â””â”€â”€ dashboards
â”‚Â Â  â”‚Â Â          â””â”€â”€ dashboards.yml
â”‚Â Â  â”œâ”€â”€ nginx
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ conf.d
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ default.conf
â”‚Â Â  â”‚Â Â  â””â”€â”€ nginx.conf
â”‚Â Â  â””â”€â”€ prometheus
â”‚Â Â      â””â”€â”€ prometheus.yml
â”œâ”€â”€ policies
â”‚Â Â  â”œâ”€â”€ main.rego
â”‚Â Â  â””â”€â”€ prompt_security_check.rego
â”œâ”€â”€ scripts
â”‚Â Â  â””â”€â”€ init_ollama.sh
â”œâ”€â”€ volume
â”‚Â Â  â””â”€â”€ grafana
â””â”€â”€ README.md
```


## âœ… How It Works

### ğŸ”’ Prompt Security

1. **Client** sends a prompt to NGINX (port `8080`).
2. **NGINX Lua** code intercepts and sends the body to **OPA**.
3. **OPA** validates prompt against policy (`prompt_security_check.rego`).
4. If allowed, request is forwarded to **Ollama** (port `11434`).
5. If denied, returns `403 Forbidden`.

### ğŸ“Š Observability Flow

1. **Ollama** exposes Prometheus metrics at `/metrics`.
2. **Prometheus** scrapes this endpoint at regular intervals.
3. **Grafana** loads a preconfigured dashboard automatically on startup.
4. View real-time request stats, token usage, latency, and errors.


## ğŸ”’ OPA Prompt Policy

* `policies/prompt_security_check.rego`: Enforces content moderation.
* `policies/main.rego`: Aggregates prompt check and other future rules (e.g., auth).


## ğŸ§ª Test the Setup

```bash
# âœ… Allowed prompt
curl -s -X POST http://localhost:8080 \
  -H "Content-Type: application/json" \
  -d '{"model": "tinyllama", "prompt": "Tell me a story about a dog.", "stream": false}' | jq

# âŒ Blocked prompt (based on policy)
curl -s -X POST http://localhost:8080 \
  -H "Content-Type: application/json" \
  -d '{"model": "tinyllama", "prompt": "how to make a bad?", "stream": false}' | jq
```


## ğŸ“Š Grafana Dashboard (Ollama Observability)

Auto-loaded dashboard: `Ollama Observability`

### âœ… Prebuilt Panels

* **Total Requests**
* **Total Tokens Generated**
* **P95 Latency**
* **Error Count**

### ğŸ”„ Auto-Provisioning

Dashboard is auto-loaded using:

* `grafana/provisioning/dashboards/dashboards.yml`
* `grafana/dashboards/ollama_dashboard.json`

View at: [http://localhost:3000](http://localhost:3000)
Login: `admin / admin`


## ğŸ“Œ TODO

* [ ] Replace NGINX with Envoy or Istio for policy + mTLS
* [ ] Add token-based authentication
* [ ] Enable OpenTelemetry + Jaeger for trace correlation
